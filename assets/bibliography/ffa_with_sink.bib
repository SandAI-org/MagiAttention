@misc{xiao2024efficientstreaminglanguagemodels,
      title={Efficient Streaming Language Models with Attention Sinks}, 
      author={Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis},
      year={2024},
      eprint={2309.17453},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.17453}, 
}

@misc{gu2025attentionsinkemergeslanguage,
      title={When Attention Sink Emerges in Language Models: An Empirical View}, 
      author={Xiangming Gu and Tianyu Pang and Chao Du and Qian Liu and Fengzhuo Zhang and Cunxiao Du and Ye Wang and Min Lin},
      year={2025},
      eprint={2410.10781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.10781}, 
}

@misc{miller2025attentionmisc,
  author       = {Evan Miller},
  title        = {Attention is Off by One},
  howpublished = {\url{https://www.evanmiller.org/attention-is-off-by-one.html}},
  year         = {2024},
  month        = {july},
}

